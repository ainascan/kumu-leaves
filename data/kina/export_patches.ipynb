{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import deltalake as dl\n",
    "import boto3\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import s3fs\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "session = boto3.Session(profile_name='default')\n",
    "credentials = session.get_credentials()\n",
    "credentials = credentials.get_frozen_credentials()\n",
    "\n",
    "storage_options = {\n",
    "    'AWS_REGION': 'us-west-1',\n",
    "    'AWS_ACCESS_KEY_ID': credentials.access_key,\n",
    "    'AWS_SECRET_ACCESS_KEY': credentials.secret_key,\n",
    "    'AWS_S3_ALLOW_UNSAFE_RENAME': 'true'\n",
    "}\n",
    "\n",
    "s3 = s3fs.S3FileSystem(\n",
    "    anon=False,\n",
    "    use_ssl=False,\n",
    "    key=storage_options['AWS_ACCESS_KEY_ID'],\n",
    "    secret=storage_options['AWS_SECRET_ACCESS_KEY'],\n",
    "    client_kwargs={\n",
    "        'region_name': storage_options['AWS_REGION']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "import hashlib\n",
    "import cv2\n",
    "\n",
    "def is_valid_contour(contour):\n",
    "    try:\n",
    "        if contour is None:\n",
    "            return False\n",
    "            \n",
    "        if len(contour) < 24:\n",
    "            return False\n",
    "\n",
    "        if not Polygon(contour).is_valid:\n",
    "            return False\n",
    "\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def compute_hash(row):\n",
    "    image_path = row['image_path']\n",
    "    contour = row['contour'].copy()\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    contour[:, 0] -= x\n",
    "    contour[:, 1] -= y\n",
    "\n",
    "    contour_hash = hashlib.md5(contour.flatten().astype('uint8')).hexdigest()\n",
    "    image_path_hash = hashlib.md5(image_path.encode()).hexdigest()\n",
    "    mask_hash = hashlib.md5(f'{contour_hash}{image_path_hash}'.encode()).hexdigest()\n",
    "    return mask_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2024-10-07T21:47:55Z \u001b[33mWARN \u001b[0m aws_config::imds::region\u001b[90m]\u001b[0m failed to load region from IMDS err=failed to load IMDS session token: dispatch failure: timeout: error trying to connect: HTTP connect timeout occurred after 1s: HTTP connect timeout occurred after 1s: timed out (FailedToLoadToken(FailedToLoadToken { source: DispatchFailure(DispatchFailure { source: ConnectorError { kind: Timeout, source: hyper::Error(Connect, HttpTimeoutError { kind: \"HTTP connect\", duration: 1s }), connection: Unknown } }) }))\n",
      "\u001b[90m[\u001b[0m2024-10-07T21:47:56Z \u001b[33mWARN \u001b[0m aws_config::imds::region\u001b[90m]\u001b[0m failed to load region from IMDS err=failed to load IMDS session token: dispatch failure: timeout: error trying to connect: HTTP connect timeout occurred after 1s: HTTP connect timeout occurred after 1s: timed out (FailedToLoadToken(FailedToLoadToken { source: DispatchFailure(DispatchFailure { source: ConnectorError { kind: Timeout, source: hyper::Error(Connect, HttpTimeoutError { kind: \"HTTP connect\", duration: 1s }), connection: Unknown } }) }))\n",
      "\u001b[90m[\u001b[0m2024-10-07T21:47:57Z \u001b[33mWARN \u001b[0m aws_config::imds::region\u001b[90m]\u001b[0m failed to load region from IMDS err=failed to load IMDS session token: dispatch failure: timeout: error trying to connect: HTTP connect timeout occurred after 1s: HTTP connect timeout occurred after 1s: timed out (FailedToLoadToken(FailedToLoadToken { source: DispatchFailure(DispatchFailure { source: ConnectorError { kind: Timeout, source: hyper::Error(Connect, HttpTimeoutError { kind: \"HTTP connect\", duration: 1s }), connection: Unknown } }) }))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Contour Annotations: 13858\n",
      "Total Patch Annotations: 13346\n",
      "Total Defective Patches: 5076\n",
      "Total Healthy Patches: 8270\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>patch</th>\n",
       "      <th>defective</th>\n",
       "      <th>hash</th>\n",
       "      <th>contour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coffee-dataset/raw_images/bay_view_dead_leaves...</td>\n",
       "      <td>[230, 77, 294, 141]</td>\n",
       "      <td>1</td>\n",
       "      <td>ec2785912ccfc157520dc7e44985fbd6</td>\n",
       "      <td>[[1939, 651], [1938, 652], [1935, 652], [1934,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coffee-dataset/raw_images/bay_view_dead_leaves...</td>\n",
       "      <td>[179, 76, 243, 140]</td>\n",
       "      <td>1</td>\n",
       "      <td>ec2785912ccfc157520dc7e44985fbd6</td>\n",
       "      <td>[[1939, 651], [1938, 652], [1935, 652], [1934,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coffee-dataset/raw_images/bay_view_dead_leaves...</td>\n",
       "      <td>[115, 75, 179, 139]</td>\n",
       "      <td>1</td>\n",
       "      <td>ec2785912ccfc157520dc7e44985fbd6</td>\n",
       "      <td>[[1939, 651], [1938, 652], [1935, 652], [1934,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coffee-dataset/raw_images/bay_view_dead_leaves...</td>\n",
       "      <td>[62, 72, 126, 136]</td>\n",
       "      <td>1</td>\n",
       "      <td>ec2785912ccfc157520dc7e44985fbd6</td>\n",
       "      <td>[[1939, 651], [1938, 652], [1935, 652], [1934,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coffee-dataset/raw_images/bay_view_dead_leaves...</td>\n",
       "      <td>[99, 98, 163, 162]</td>\n",
       "      <td>1</td>\n",
       "      <td>ec2785912ccfc157520dc7e44985fbd6</td>\n",
       "      <td>[[1939, 651], [1938, 652], [1935, 652], [1934,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13341</th>\n",
       "      <td>coffee-dataset/raw_images/milolii_luis_farm/20...</td>\n",
       "      <td>[500, 382, 564, 446]</td>\n",
       "      <td>0</td>\n",
       "      <td>d36ae6fcc22a404233638f984e7b39b7</td>\n",
       "      <td>[[1095, 1474], [1084, 1489], [1076, 1502], [10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13342</th>\n",
       "      <td>coffee-dataset/raw_images/milolii_luis_farm/20...</td>\n",
       "      <td>[527, 304, 591, 368]</td>\n",
       "      <td>0</td>\n",
       "      <td>d36ae6fcc22a404233638f984e7b39b7</td>\n",
       "      <td>[[1095, 1474], [1084, 1489], [1076, 1502], [10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13343</th>\n",
       "      <td>coffee-dataset/raw_images/milolii_luis_farm/20...</td>\n",
       "      <td>[600, 249, 664, 313]</td>\n",
       "      <td>0</td>\n",
       "      <td>d36ae6fcc22a404233638f984e7b39b7</td>\n",
       "      <td>[[1095, 1474], [1084, 1489], [1076, 1502], [10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13344</th>\n",
       "      <td>coffee-dataset/raw_images/milolii_luis_farm/20...</td>\n",
       "      <td>[250, 102, 314, 166]</td>\n",
       "      <td>0</td>\n",
       "      <td>d36ae6fcc22a404233638f984e7b39b7</td>\n",
       "      <td>[[1095, 1474], [1084, 1489], [1076, 1502], [10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13345</th>\n",
       "      <td>coffee-dataset/raw_images/milolii_luis_farm/20...</td>\n",
       "      <td>[175, 66, 239, 130]</td>\n",
       "      <td>0</td>\n",
       "      <td>d36ae6fcc22a404233638f984e7b39b7</td>\n",
       "      <td>[[1095, 1474], [1084, 1489], [1076, 1502], [10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13320 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_path  \\\n",
       "0      coffee-dataset/raw_images/bay_view_dead_leaves...   \n",
       "1      coffee-dataset/raw_images/bay_view_dead_leaves...   \n",
       "2      coffee-dataset/raw_images/bay_view_dead_leaves...   \n",
       "3      coffee-dataset/raw_images/bay_view_dead_leaves...   \n",
       "4      coffee-dataset/raw_images/bay_view_dead_leaves...   \n",
       "...                                                  ...   \n",
       "13341  coffee-dataset/raw_images/milolii_luis_farm/20...   \n",
       "13342  coffee-dataset/raw_images/milolii_luis_farm/20...   \n",
       "13343  coffee-dataset/raw_images/milolii_luis_farm/20...   \n",
       "13344  coffee-dataset/raw_images/milolii_luis_farm/20...   \n",
       "13345  coffee-dataset/raw_images/milolii_luis_farm/20...   \n",
       "\n",
       "                      patch  defective                              hash  \\\n",
       "0       [230, 77, 294, 141]          1  ec2785912ccfc157520dc7e44985fbd6   \n",
       "1       [179, 76, 243, 140]          1  ec2785912ccfc157520dc7e44985fbd6   \n",
       "2       [115, 75, 179, 139]          1  ec2785912ccfc157520dc7e44985fbd6   \n",
       "3        [62, 72, 126, 136]          1  ec2785912ccfc157520dc7e44985fbd6   \n",
       "4        [99, 98, 163, 162]          1  ec2785912ccfc157520dc7e44985fbd6   \n",
       "...                     ...        ...                               ...   \n",
       "13341  [500, 382, 564, 446]          0  d36ae6fcc22a404233638f984e7b39b7   \n",
       "13342  [527, 304, 591, 368]          0  d36ae6fcc22a404233638f984e7b39b7   \n",
       "13343  [600, 249, 664, 313]          0  d36ae6fcc22a404233638f984e7b39b7   \n",
       "13344  [250, 102, 314, 166]          0  d36ae6fcc22a404233638f984e7b39b7   \n",
       "13345   [175, 66, 239, 130]          0  d36ae6fcc22a404233638f984e7b39b7   \n",
       "\n",
       "                                                 contour  \n",
       "0      [[1939, 651], [1938, 652], [1935, 652], [1934,...  \n",
       "1      [[1939, 651], [1938, 652], [1935, 652], [1934,...  \n",
       "2      [[1939, 651], [1938, 652], [1935, 652], [1934,...  \n",
       "3      [[1939, 651], [1938, 652], [1935, 652], [1934,...  \n",
       "4      [[1939, 651], [1938, 652], [1935, 652], [1934,...  \n",
       "...                                                  ...  \n",
       "13341  [[1095, 1474], [1084, 1489], [1076, 1502], [10...  \n",
       "13342  [[1095, 1474], [1084, 1489], [1076, 1502], [10...  \n",
       "13343  [[1095, 1474], [1084, 1489], [1076, 1502], [10...  \n",
       "13344  [[1095, 1474], [1084, 1489], [1076, 1502], [10...  \n",
       "13345  [[1095, 1474], [1084, 1489], [1076, 1502], [10...  \n",
       "\n",
       "[13320 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = dl.DeltaTable(\n",
    "    table_uri='s3a://coffee-dataset/lake/raw_annotations',\n",
    "    storage_options=storage_options\n",
    ").to_pandas()\n",
    "\n",
    "print('Total Contour Annotations:', len(annotations))\n",
    "\n",
    "try:\n",
    "    patch_annos = dl.DeltaTable(\n",
    "        table_uri='s3a://coffee-dataset/lake/clear_leaf_patch_annotations',\n",
    "        storage_options=storage_options\n",
    "    ).to_pandas()\n",
    "except:\n",
    "    patch_annos = pd.DataFrame(columns=['image_path', 'patch', 'defective', 'hash'])\n",
    "\n",
    "print('Total Patch Annotations:', len(patch_annos))\n",
    "print('Total Defective Patches:', len(patch_annos[patch_annos['defective'] == 1]))\n",
    "print('Total Healthy Patches:', len(patch_annos[patch_annos['defective'] == 0]))\n",
    "\n",
    "annotations = annotations[annotations['category_id'] == 'leaf']\n",
    "annotations = annotations[annotations['area'] > annotations['area'].quantile(0.05)]\n",
    "annotations['contour'] = annotations['segmentation'].apply(lambda x: np.array(x).reshape(-1, 2).astype(np.int32))\n",
    "annotations = annotations[annotations['contour'].apply(lambda x: is_valid_contour(x))]\n",
    "annotations['hash'] = annotations.apply(compute_hash, axis=1)\n",
    "annotations = annotations[['image_path', 'hash', 'contour']]\n",
    "\n",
    "annotations.reset_index(drop=True, inplace=True)\n",
    "patch_annos.reset_index(drop=True, inplace=True)\n",
    "\n",
    "patch_annos = patch_annos.merge(annotations, on='hash', how='left', suffixes=('_patch', ''))\n",
    "\n",
    "patch_annos = patch_annos[['image_path', 'patch', 'defective', 'hash', 'contour']]\n",
    "\n",
    "# drop nan values\n",
    "patch_annos = patch_annos.dropna()\n",
    "\n",
    "patch_annos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('patches', exist_ok=True)\n",
    "os.makedirs('patches/defective', exist_ok=True)\n",
    "os.makedirs('patches/healthy', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13320/13320 [07:07<00:00, 31.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "t = 64\n",
    "\n",
    "loader = tqdm(total=len(patch_annos), position=0, leave=True)\n",
    "\n",
    "for hash, pdf in patch_annos.groupby('hash'):\n",
    "    image_path = pdf.image_path.iloc[0]\n",
    "    contour = pdf.contour.iloc[0].copy()\n",
    "\n",
    "    with s3.open(image_path, 'rb') as f:\n",
    "        image = Image.open(f)\n",
    "        image = ImageOps.exif_transpose(image)\n",
    "        image = np.array(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    patches = pdf['patch'].values\n",
    "    defectives = pdf['defective'].values\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(contour.astype(int))\n",
    "    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "    mask = cv2.drawContours(mask, [contour.astype(int)], -1, (255), -1)\n",
    "    mask = cv2.bitwise_and(image, image, mask=mask)\n",
    "    mask = mask[y:y+h, x:x+w]\n",
    "\n",
    "    contour[:, 0] -= x\n",
    "    contour[:, 1] -= y\n",
    "    \n",
    "    polygon = Polygon(contour)\n",
    "\n",
    "    tiles = []\n",
    "    \n",
    "    for i, (patch, defective) in enumerate(zip(patches, defectives)):        \n",
    "        loader.update(1)\n",
    "\n",
    "        x1, y1, x2, y2 = patch\n",
    "        box = Polygon([(x1, y1), (x2, y1), (x2, y2), (x1, y2)])\n",
    "        intersection = box.intersection(polygon)\n",
    "        \n",
    "        greater_than_half = intersection.area / box.area >= 0.5\n",
    "        inside_polygon = polygon.contains(box)\n",
    "        \n",
    "        if greater_than_half or inside_polygon:\n",
    "            tile = mask[y1:y2, x1:x2]\n",
    "\n",
    "            # if any size is less than t//2, skip\n",
    "            if tile.shape[0] < t//2 or tile.shape[1] < t//2:\n",
    "                continue\n",
    "\n",
    "            # if tile is all black, skip\n",
    "            if np.all(tile == 0):\n",
    "                continue\n",
    "\n",
    "            pads = ((0, t - tile.shape[0]), (0, t - tile.shape[1]), (0, 0))\n",
    "            tile = np.pad(tile, pads, 'constant', constant_values=(0, 0))\n",
    "\n",
    "            if defective:\n",
    "                cv2.imwrite(f'patches/defective/{hash}_{i}.png', tile)\n",
    "            else:\n",
    "                cv2.imwrite(f'patches/healthy/{hash}_{i}.png', tile)\n",
    "        \n",
    "loader.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datadev-5ox7fytP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
